{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf2b410e-1e70-4dbf-9a23-22868e7c90b1",
   "metadata": {},
   "source": [
    "## DataFrame Mini Project: Twitter Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19991ab1-8751-42ce-8bad-cf3e415d99af",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "* required-libraries\n",
    "* connect-api\n",
    "* call-api\n",
    "* read-dumped-data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d886537-c201-4fbd-8747-646f18733d6f",
   "metadata": {},
   "source": [
    "# Required Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cf1f22-1d2d-4335-a010-2827fb87a5d4",
   "metadata": {},
   "source": [
    "Twitter has API that you can use to extract tweets and users. Here we are using tweepy library to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2664650f-6ab8-4e3b-a451-8cdc8e6af80d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tweepy\n",
      "  Downloading tweepy-4.14.0-py3-none-any.whl (98 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.5/98.5 kB\u001b[0m \u001b[31m329.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting oauthlib<4,>=3.2.0 (from tweepy)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m459.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.27.0 in /home/zahrafouladian/miniconda3/envs/py310/lib/python3.10/site-packages (from tweepy) (2.31.0)\n",
      "Collecting requests-oauthlib<2,>=1.2.0 (from tweepy)\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/zahrafouladian/miniconda3/envs/py310/lib/python3.10/site-packages (from requests<3,>=2.27.0->tweepy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/zahrafouladian/miniconda3/envs/py310/lib/python3.10/site-packages (from requests<3,>=2.27.0->tweepy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/zahrafouladian/miniconda3/envs/py310/lib/python3.10/site-packages (from requests<3,>=2.27.0->tweepy) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/zahrafouladian/miniconda3/envs/py310/lib/python3.10/site-packages (from requests<3,>=2.27.0->tweepy) (2023.7.22)\n",
      "Installing collected packages: oauthlib, requests-oauthlib, tweepy\n",
      "Successfully installed oauthlib-3.2.2 requests-oauthlib-1.3.1 tweepy-4.14.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23baa396-9b5b-464b-87dd-edde1b06ed3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16da0af5-0e4d-4acf-a8f3-128473d9491e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f28b4d8-d14a-4467-aa20-6e7721fdc43b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Connect to the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e36e324-4cc2-4be8-bcf9-c1e9bfd94c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONSUMER_KEY = os.environ['CONSUMER_KEY']\n",
    "CONSUMER_SECRET = os.environ['CONSUMER_SECRET']\n",
    "ACCESS_TOKEN = os.environ['ACCESS_TOKEN']\n",
    "ACCESS_TOKEN_SECRET = os.environ['ACCESS_TOKEN_SECRET']\n",
    "BEARER_TOKEN = os.environ['BEARER_TOKEN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a7a472-26d6-48d8-8962-6f8189902d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269e9470-6d80-433c-9822-48ae6e67fea0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Call the API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34afeb67-1664-4497-b9be-247810f26d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = []\n",
    "dump_path = Path('./data/twitter_data/')\n",
    "if not dump_path.exists():\n",
    "    dump_path.mkdir()\n",
    "\n",
    "for page in tqdm(tweepy.Cursor(\n",
    "    api.search_tweets,\n",
    "    tweet_mode='extended',\n",
    "    q = \"#machine_learning\",\n",
    "    count = 10,\n",
    "    # lang=\"en\",\n",
    ").pages(2)):\n",
    "    for tweet in page:\n",
    "        json_data = tweet._json\n",
    "        with open(dump_path / f'{json_data[\"id\"]}.json', 'w') as f:\n",
    "            json.dump(json_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d249232b-bdb4-4e54-8958-43f374f1cba7",
   "metadata": {},
   "source": [
    "# Read Dumped Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a840ce7-57e6-42ab-b054-9c6e229413b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path = Path('./data/twitter_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d55044a-f13f-49ae-9fb0-743412371f68",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:00, 104.62it/s]\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "for file_path in tqdm(data_path.iterdir()):\n",
    "    if file_path.is_dir():\n",
    "        continue\n",
    "    with open(file_path) as f:\n",
    "        d = json.load(f)    \n",
    "    rows.append(dict(\n",
    "        name = d['user']['name'],\n",
    "        followers = d['user']['followers_count'],\n",
    "        following = d['user']['friends_count'],\n",
    "        follower_following_ratio =  d['user']['followers_count'] / (d['user']['friends_count'] + 1),\n",
    "        text = d.get('full_text') or d.get('text'),\n",
    "        hashtags = list(map(lambda item: item['text'], d['entities']['hashtags'])),\n",
    "        likes = d['favorite_count'],\n",
    "        retweets = d['retweet_count'],\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0df60235-51e5-424d-955c-a35d6d74ed55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "36b99895-ddbc-4ebb-8ac9-039030808360",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.min_rows', 20)\n",
    "pd.set_option('display.max_colwidth', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5120eeb2-ec03-4b9e-9f7d-0e00f0198c18",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>followers</th>\n",
       "      <th>following</th>\n",
       "      <th>follower_following_ratio</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lucifer AI</td>\n",
       "      <td>37</td>\n",
       "      <td>194</td>\n",
       "      <td>0.189744</td>\n",
       "      <td>#30DaysOfCodechallenge\\nDay22\\nNot done much t...</td>\n",
       "      <td>[30DaysOfCodechallenge, 30Daysofcode, machine_...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Coding Buddy</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>RT @lucifer_twtt: #30DaysOfCodechallenge\\nDay2...</td>\n",
       "      <td>[30DaysOfCodechallenge, 30Daysofcode]</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AI Bot by uCloudify.com</td>\n",
       "      <td>991</td>\n",
       "      <td>0</td>\n",
       "      <td>991.000000</td>\n",
       "      <td>RT @lucifer_twtt: #30DaysOfCodechallenge\\nDay2...</td>\n",
       "      <td>[30DaysOfCodechallenge, 30Daysofcode]</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#30DaysOfCode</td>\n",
       "      <td>2318</td>\n",
       "      <td>1</td>\n",
       "      <td>1159.000000</td>\n",
       "      <td>RT @lucifer_twtt: #30DaysOfCodechallenge\\nDay2...</td>\n",
       "      <td>[30DaysOfCodechallenge, 30Daysofcode]</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PyBot</td>\n",
       "      <td>902</td>\n",
       "      <td>1</td>\n",
       "      <td>451.000000</td>\n",
       "      <td>RT @lucifer_twtt: #30DaysOfCodechallenge\\nDay2...</td>\n",
       "      <td>[30DaysOfCodechallenge, 30Daysofcode]</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mr Data Scientist</td>\n",
       "      <td>10965</td>\n",
       "      <td>270</td>\n",
       "      <td>40.461255</td>\n",
       "      <td>RT @lucifer_twtt: #30DaysOfCodechallenge\\nDay2...</td>\n",
       "      <td>[30DaysOfCodechallenge, 30Daysofcode]</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SUPER WRITERS</td>\n",
       "      <td>178</td>\n",
       "      <td>441</td>\n",
       "      <td>0.402715</td>\n",
       "      <td>We can complete your;\\n#Homework \\n#Machine_Le...</td>\n",
       "      <td>[Homework, Machine_Learning, Data_Science, Ass...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PyBot</td>\n",
       "      <td>902</td>\n",
       "      <td>1</td>\n",
       "      <td>451.000000</td>\n",
       "      <td>RT @superwriterz: We can complete your;\\n#Home...</td>\n",
       "      <td>[Homework, Machine_Learning, Data_Science, Ass...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Xeron Bot</td>\n",
       "      <td>2309</td>\n",
       "      <td>1</td>\n",
       "      <td>1154.500000</td>\n",
       "      <td>RT @superwriterz: We can complete your;\\n#Home...</td>\n",
       "      <td>[Homework, Machine_Learning, Data_Science, Ass...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>//InsertUsefulComment</td>\n",
       "      <td>45</td>\n",
       "      <td>212</td>\n",
       "      <td>0.211268</td>\n",
       "      <td>RT @SmitterHane: Just use it\\n#DataScience #Co...</td>\n",
       "      <td>[DataScience, CodeNewbie, code, 100DaysOfCode,...</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>STATS HOMEWORK HELPERS</td>\n",
       "      <td>36</td>\n",
       "      <td>210</td>\n",
       "      <td>0.170616</td>\n",
       "      <td>We can complete your;\\n#Homework \\n#Machine_Le...</td>\n",
       "      <td>[Homework, Machine_Learning, Data_Science, Ass...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Akintayo</td>\n",
       "      <td>68</td>\n",
       "      <td>36</td>\n",
       "      <td>1.837838</td>\n",
       "      <td>RT @stats_helpers: We can complete your;\\n#Hom...</td>\n",
       "      <td>[Homework, Machine_Learning, Data_Science, Ass...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Read Tech Here</td>\n",
       "      <td>815</td>\n",
       "      <td>310</td>\n",
       "      <td>2.620579</td>\n",
       "      <td>RT @stats_helpers: We can complete your;\\n#Hom...</td>\n",
       "      <td>[Homework, Machine_Learning, Data_Science, Ass...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Unemployed Professor</td>\n",
       "      <td>29</td>\n",
       "      <td>176</td>\n",
       "      <td>0.163842</td>\n",
       "      <td>Let's handle your;\\n#Homework \\n#Machine_Learn...</td>\n",
       "      <td>[Homework, Machine_Learning, Data_Science, Ass...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Utibe-Abasi Jacob Udoh</td>\n",
       "      <td>423</td>\n",
       "      <td>888</td>\n",
       "      <td>0.475816</td>\n",
       "      <td>RT @Tutor_Nolan: Let's handle your;\\n#Homework...</td>\n",
       "      <td>[Homework, Machine_Learning, Data_Science, Ass...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Xeron Bot</td>\n",
       "      <td>2309</td>\n",
       "      <td>1</td>\n",
       "      <td>1154.500000</td>\n",
       "      <td>RT @Tutor_Nolan: Let's handle your;\\n#Homework...</td>\n",
       "      <td>[Homework, Machine_Learning, Data_Science, Ass...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ام محمد</td>\n",
       "      <td>35</td>\n",
       "      <td>87</td>\n",
       "      <td>0.397727</td>\n",
       "      <td>RT @AshwagAlbukhari: 📍📍📍\\nhappening now as par...</td>\n",
       "      <td>[Ai, precision_medicine]</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Fermentation</td>\n",
       "      <td>359</td>\n",
       "      <td>539</td>\n",
       "      <td>0.664815</td>\n",
       "      <td>An article entitled \"Predicting #Alcohol Conce...</td>\n",
       "      <td>[Alcohol, Beer_Fermentation, Machine_Learning]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Lonewollff🥑</td>\n",
       "      <td>539</td>\n",
       "      <td>3479</td>\n",
       "      <td>0.154885</td>\n",
       "      <td>@datawithsuman @SaveToNotion  #machine_learning</td>\n",
       "      <td>[machine_learning]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>وايت جولد | خدمات برمجية</td>\n",
       "      <td>261</td>\n",
       "      <td>570</td>\n",
       "      <td>0.457093</td>\n",
       "      <td>🔗نقدم المساعدة لطلبة #الدراسات_العليا في مجال ...</td>\n",
       "      <td>[الدراسات_العليا, الهندسة, المشاريع, البحوث, M...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        name  followers  following  follower_following_ratio  \\\n",
       "0                 Lucifer AI         37        194                  0.189744   \n",
       "1               Coding Buddy          9          2                  3.000000   \n",
       "2    AI Bot by uCloudify.com        991          0                991.000000   \n",
       "3              #30DaysOfCode       2318          1               1159.000000   \n",
       "4                      PyBot        902          1                451.000000   \n",
       "5          Mr Data Scientist      10965        270                 40.461255   \n",
       "6              SUPER WRITERS        178        441                  0.402715   \n",
       "7                      PyBot        902          1                451.000000   \n",
       "8                  Xeron Bot       2309          1               1154.500000   \n",
       "9      //InsertUsefulComment         45        212                  0.211268   \n",
       "10    STATS HOMEWORK HELPERS         36        210                  0.170616   \n",
       "11                  Akintayo         68         36                  1.837838   \n",
       "12            Read Tech Here        815        310                  2.620579   \n",
       "13      Unemployed Professor         29        176                  0.163842   \n",
       "14    Utibe-Abasi Jacob Udoh        423        888                  0.475816   \n",
       "15                 Xeron Bot       2309          1               1154.500000   \n",
       "16                   ام محمد         35         87                  0.397727   \n",
       "17              Fermentation        359        539                  0.664815   \n",
       "18               Lonewollff🥑        539       3479                  0.154885   \n",
       "19  وايت جولد | خدمات برمجية        261        570                  0.457093   \n",
       "\n",
       "                                                 text  \\\n",
       "0   #30DaysOfCodechallenge\\nDay22\\nNot done much t...   \n",
       "1   RT @lucifer_twtt: #30DaysOfCodechallenge\\nDay2...   \n",
       "2   RT @lucifer_twtt: #30DaysOfCodechallenge\\nDay2...   \n",
       "3   RT @lucifer_twtt: #30DaysOfCodechallenge\\nDay2...   \n",
       "4   RT @lucifer_twtt: #30DaysOfCodechallenge\\nDay2...   \n",
       "5   RT @lucifer_twtt: #30DaysOfCodechallenge\\nDay2...   \n",
       "6   We can complete your;\\n#Homework \\n#Machine_Le...   \n",
       "7   RT @superwriterz: We can complete your;\\n#Home...   \n",
       "8   RT @superwriterz: We can complete your;\\n#Home...   \n",
       "9   RT @SmitterHane: Just use it\\n#DataScience #Co...   \n",
       "10  We can complete your;\\n#Homework \\n#Machine_Le...   \n",
       "11  RT @stats_helpers: We can complete your;\\n#Hom...   \n",
       "12  RT @stats_helpers: We can complete your;\\n#Hom...   \n",
       "13  Let's handle your;\\n#Homework \\n#Machine_Learn...   \n",
       "14  RT @Tutor_Nolan: Let's handle your;\\n#Homework...   \n",
       "15  RT @Tutor_Nolan: Let's handle your;\\n#Homework...   \n",
       "16  RT @AshwagAlbukhari: 📍📍📍\\nhappening now as par...   \n",
       "17  An article entitled \"Predicting #Alcohol Conce...   \n",
       "18    @datawithsuman @SaveToNotion  #machine_learning   \n",
       "19  🔗نقدم المساعدة لطلبة #الدراسات_العليا في مجال ...   \n",
       "\n",
       "                                             hashtags  likes  retweets  \n",
       "0   [30DaysOfCodechallenge, 30Daysofcode, machine_...      0         5  \n",
       "1               [30DaysOfCodechallenge, 30Daysofcode]      0         5  \n",
       "2               [30DaysOfCodechallenge, 30Daysofcode]      0         5  \n",
       "3               [30DaysOfCodechallenge, 30Daysofcode]      0         5  \n",
       "4               [30DaysOfCodechallenge, 30Daysofcode]      0         5  \n",
       "5               [30DaysOfCodechallenge, 30Daysofcode]      0         5  \n",
       "6   [Homework, Machine_Learning, Data_Science, Ass...      0         2  \n",
       "7   [Homework, Machine_Learning, Data_Science, Ass...      0         2  \n",
       "8   [Homework, Machine_Learning, Data_Science, Ass...      0         2  \n",
       "9   [DataScience, CodeNewbie, code, 100DaysOfCode,...      0        24  \n",
       "10  [Homework, Machine_Learning, Data_Science, Ass...      0         2  \n",
       "11  [Homework, Machine_Learning, Data_Science, Ass...      0         2  \n",
       "12  [Homework, Machine_Learning, Data_Science, Ass...      0         2  \n",
       "13  [Homework, Machine_Learning, Data_Science, Ass...      0         2  \n",
       "14  [Homework, Machine_Learning, Data_Science, Ass...      0         2  \n",
       "15  [Homework, Machine_Learning, Data_Science, Ass...      0         2  \n",
       "16                           [Ai, precision_medicine]      0        10  \n",
       "17     [Alcohol, Beer_Fermentation, Machine_Learning]      0         0  \n",
       "18                                 [machine_learning]      0         0  \n",
       "19  [الدراسات_العليا, الهندسة, المشاريع, البحوث, M...      0         0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3830c012-f8c2-43ee-bc86-3118cb715f9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
